---
title: "STA 141A Final Project"
author: "Ian Xu, Nazil Luqman, Victoria Yeo, Jeffrey Ugochukwu"
date: "12/18/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(stargazer)
```

## Contributions

Victoria Yeo: Data Analysis, Interpretation
Ian Xu: Interpretation,Linear Regression Modeling, Project Manager
Jeffrey Ugochukwu: Data Analysis, Conclusion 
Nazil Luqman: Data Management, Interpretation, Aesthetics

## Introduction

With anime expanding internationally over the last couple decades, one might think that the anime industry is fairing well. Yet, in "11+ Anime Comapnies and Studios that went Bankrupt in the Last 4 Decades," Theo Ellis, found of Anime Motivation, states that the "anime indsutry is a mess" due to reasons like high piracy of anime, low budgets, the average anime costing $1M dollars to produce, and some companies having difficulty paying employees and staying afloat. Ellis notes that "In the last 5+ years, anime companies have gone bankrupt more than ever." 

The problem for anime studios is that they face a constraint one. With limited resources and hundreds of different production options, among which inlude 43 different genres and a virtually infinite number  genre combinations,  anime studios must determine what genre animes to produce that will garner enough interest to help them stay afloat and generate a positive rate of return. The objective of this project is decipher the data to help anime studios make better decisions in determining what animes to produce.

## Questions of Interest

There are two key questions that we hope to answer:

* What effect do each of the 43 different genres have on anime popularity?
* What model is best at predicting future observations of anime popularity?

## Dataset

Our dataset, found on Kaggle, is based on MyAnimeList.net, a website that allows members to score anime and manga. While the dataset includes many variables for each observation (6668 total observations), we found that some variables were inappropriate to include in this study (e.g. one variable contained website links to respective anime posters). Therefore, we have reduced the dataset to include the following variables:

* Popularity of Anime ($members$)
* Medium type ($type$) [Movie, Music, ONA, OVA, Special, TV]
* Anime source ($source$) [4-koma manga, Book, Card game, Digital manga, Game, Light novel, Manga, Music, Novel, Original, Other, Picture book, Radio, Visual novel, Web manga]
* Current airing status ($status$) [Currently Airing, Finished Airing]
* Age rating ($rating$) [G - All Ages, None, PG - Children, PG - 13 - Teens 13 or older, R - 17+ (violence & profanity), R+ - Mild Nudity, Rx - Hentai]
* Anime genre ($genre$) [Action, Adventure, Cars,Comedy, Dementia, Demons, Drama, Ecchi, Fantasy, Game, Harem, Hentai, Historical, Horror, Josei, Kids, Magic, Martial Arts, Mecha, Military, Music, Mystery, Parody, Police, Psychological, Romance, Samurai, School, Sci-Fi, Seinen, Shoujo, Shoujo Ai, Shounen, Shounen Ai, Slice of Life, Space, Sports, Super Power, Supernatural, Thriller, Vampire, Yaoi, Yuri, None]
* Year anime aired ($yearAired$) [1942, 1943, 1944, 1945, 1957, 1958,..., 2018]
* Number of episodes ($episodes$) 
* Average rating out of 10 ($score$)
* Number of producers ($producerCount$)
* Number of licensors ($licensorCount$)
* Number of studios ($studioCount$)
* Number of genres anime encompasses ($genreCount$)
* Airing time, number of minutes ($duration$)

Because $type$, $source$, $status$, and $rating$ are categorical variables, we have to create a "baseline" case to avoid perfect collinearity. The baseline case is:

* $type$ = Movie
* $source$ = 4-koma manga
* $status$ = Currently Airing
* $rating$ = G - All Ages
* $genre$ = None
* $yearAired$ = 1942

## Causal Inference

To answer the first question of what effects different genres have on popularity ($members$), we will be conducting causal inference. With this in mind, the primary focus is whether or not our model violates any of the Gauss Markov assumptions required for OLS to be BLUE. Let's first start with defining our $x$ variables (for simplification purposes).

Let's let:

\usepackage{amsmath}

\begin{equation*}
  x_i =
  \begin{cases}
    \begin{cases}
      1 \text{ for } i= 1,...,5 & \text{ if } type = & \text{ (Music, ONA, OVA, Special, TV), respectively}\\
      \\
      1 \text{ for } i = 6,...,19 & \text{ if } source = & \text{ (Book, Card game, Digital manga, Game,}\\
      & &\text  { Light novel, Manga, Music, Novel, Original, Other,}\\
      & & \text { Picture book, Radio, Visual novel,}\\
      & & \text { Web manga), respectively}\\
      \\
      1 \text{ for } i = 20 & \text{ if } status = & \text{ Finished Airing}\\
      & \\
      1 \text{ for } i = 21,...,26 &\text { if } rating = & \text{ (None, PG - Children, PG - 13 - Teens 13 or older,}\\
      & & \text { R - 17+ (violence & profanity), R+ - Mild Nudity,}\\ 
      & & \text{ Rx - Hentai), respectively}\\
      \\
      1 \text{ for } i = 27,...,69 &\text { if } genre = & \text{ (Action, Adventure, Cars,Comedy, Dementia,}\\
      & & \text{ Demons, Drama, Ecchi, Fantasy, Game, Harem,}\\
      & & \text{ Hentai, Historical, Horror, Josei, Kids,}\\
      & & \text{ Magic, Martial Arts, Mecha, Military, Music,}\\ 
      & & \text{ Mystery, Parody, Police, Psychological, Romance,}\\ 
      & & \text{ Samurai, School, Sci-Fi, Seinen, Shoujo,}\\
      & & \text{ Shoujo Ai, Shounen, Shounen Ai, Slice of Life,}\\ 
      & & \text{ Space, Sports, Super Power, Supernatural,}\\
      & & \text{ Thriller, Vampire, Yaoi, Yuri), respectively}\\
      \\
      1 \text{ for } i = 70,...,135 &\text { if } yearAired = & \text{ (1942, 1943, 1944, 1945, 1957, 1958,..., 2018), respectively}\\
      \\
      & & \text{ }\\
    \end{cases}, 0 \text{  o.w.}\\
    \begin{cases}
    episodes &\text{ for } i = 136\\
    \\
    score &\text{ for } i = 137\\
    \\
    producerCount &\text{ for } i = 138\\
    \\
    licensorCount &\text{ for } i = 139\\
    \\
    studioCount &\text{ for } i = 140\\
    \\
    duration &\text{ for } i = 141
    \end{cases}
  \end{cases}
\end{equation*}

With that, our initial model is:
$$members = \alpha + \sum_{i=1}^{141}\beta_i x_i$$

```{r, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE)

#Getting Our Data
library(data.table)
data <- read.csv("/Users/Ian/Documents/STA 141A/FinalProjectData.csv")
genres = c("Action","Adventure", "Cars", "Comedy", "Dementia", "Demons", "Drama","Ecchi","Fantasy","Game", "Harem", "Hentai", "Historical", "Horror", "Josei", "Kids", "Magic",  "Martial Arts",  "Mecha",   "Military", "Music",   "Mystery" ,      "Parody" , "Police",  "Psychological", "Romance", "Samurai", "School",  "Sci-Fi",  "Seinen","Shoujo", "Shoujo Ai", "Shounen", "Shounen Ai", "Slice of Life", "Space" , "Sports", "Super Power", "Supernatural",  "Thriller", "Vampire", "Yaoi", "Yuri" )
data[genres] = 0
attach(data)
```

```{r, eval = FALSE}
#Inputting Genre
data$Action = ifelse(grepl("Action", genre), 1, 0)
data$Adventure = ifelse(grepl("Adventure", genre), 1, 0)
data$Cars = ifelse(grepl("Cars", genre), 1, 0)
data$Comedy = ifelse(grepl("Comedy", genre), 1, 0)
data$Dementia = ifelse(grepl("Dementia", genre), 1, 0)
data$Demons = ifelse(grepl("Demons", genre), 1, 0)
data$Drama = ifelse(grepl("Drama", genre), 1, 0)
data$Ecchi = ifelse(grepl("Ecchi", genre), 1, 0)
data$Fantasy = ifelse(grepl("Fantasy", genre), 1, 0)
data$Game = ifelse(grepl("Game", genre), 1, 0)
data$Harem = ifelse(grepl("Harem", genre), 1, 0)
data$Hentai = ifelse(grepl("Hentai", genre), 1, 0)
data$Historical = ifelse(grepl("Historical", genre), 1, 0)
data$Horror = ifelse(grepl("Horror", genre), 1, 0)
data$Josei = ifelse(grepl("Josei", genre), 1, 0)
data$Kids = ifelse(grepl("Kids", genre), 1, 0)
data$Magic = ifelse(grepl("Magic", genre), 1, 0)
data$`Martial Arts` = ifelse(grepl("Martial Arts", genre), 1, 0)
data$Mecha = ifelse(grepl("Mecha", genre), 1, 0)
data$Military = ifelse(grepl("Military", genre), 1, 0)
data$Music = ifelse(grepl("Music", genre), 1, 0)
data$Mystery = ifelse(grepl("Mystery", genre), 1, 0)
data$Parody = ifelse(grepl("Parody", genre), 1, 0)
data$Police = ifelse(grepl("Police", genre), 1, 0)
data$Psychological = ifelse(grepl("Psychological", genre), 1, 0)
data$Romance = ifelse(grepl("Romance", genre), 1, 0)
data$Samurai = ifelse(grepl("Samurai", genre), 1, 0)
data$School = ifelse(grepl("School", genre), 1, 0)
data$`Sci-Fi` = ifelse(grepl("Sci-Fi", genre), 1, 0)
data$Seinen = ifelse(grepl("Seinen", genre), 1, 0)
data$Shoujo = ifelse(grepl("Shoujo", genre), 1, 0)
data$`Shoujo Ai` = ifelse(grepl("Shoujo Ai", genre), 1, 0)
data$Shounen = ifelse(grepl("Shounen", genre), 1, 0)
data$`Shounen Ai` = ifelse(grepl("Shounen Ai", genre), 1, 0)
data$`Slice of Life` = ifelse(grepl("Slice of Life", genre), 1, 0)
data$Space = ifelse(grepl("Space", genre), 1, 0)
data$Sports = ifelse(grepl("Sports", genre), 1, 0)
data$`Super Power` = ifelse(grepl("Super Power", genre), 1, 0)
data$Supernatural = ifelse(grepl("Supernatural", genre), 1, 0)
data$Thriller = ifelse(grepl("Thriller", genre), 1, 0)
data$Vampire = ifelse(grepl("Vampire", genre), 1, 0)
data$Yaoi = ifelse(grepl("Yaoi", genre), 1, 0)
data$Yuri = ifelse(grepl("Yuri", genre), 1, 0)
```

As stated above, our first focus is whether or not our model violates the Gauss Markov assumptions. If it does, OLS will not be BLUE and the estimated coefficients of genre would not represent the true causal effect of having an anime with some specific genre. If we do find violations, we can make necessary adjustments to our model like applying Box-Cox transformation or perhaps even using a different estimator (like weighted OLS).

```{r firstModel}
firstReg = lm(members~score+source+status+favorites+producerCount+licensorCount+studioCount+genreCount+ Action + Adventure + Cars  +  Comedy  +  Dementia  +  Demons  +  Drama  + Ecchi  + Fantasy  + Game  +  Harem  + Hentai  +  Historical  +  Horror  +  Josei  +  Kids  +  Magic  +   `Martial Arts`  +   Mecha  + Military  + Music  +    Mystery   +   Parody   +  Police  +   Psychological  +  Romance  +  Samurai  + School  +   `Sci-Fi`  +   Seinen  + Shoujo  +  `Shoujo Ai`  +  Shounen  +  `Shounen Ai`  + `Slice of Life`  + Space   +  Sports  +  `Super Power`  +  Supernatural  +   Thriller  +  Vampire  + Yaoi  +  Yuri + duration + episodes + type + rating + factor(yearAired), data = data)

par(mfrow=c(2,3))
plot(firstReg)
boxplot(firstReg$residuals, main = "Boxplot of Residuals")
hist(firstReg$residuals, main = "Histogram of Residuals", xlab = "residuals")
```

It is clear from the diagnostic plots that OLS is not BLUE in this case. It is clear from the Normal Q-Q plot that the residuals are not normally distributed. From the Histogram of Residuals and Boxplot of Residuals, the residuals seem to be skewed as well. The Residuals vs Fitted and Scale-Location graph show that the residuals suffer from heteroskedasticity as well. Furthermore, from the Residuals vs Leverage plot, it appears that there are some high leverage points which likely bias our results negatively.

## Applying Box-Cox Transformation

To address these concerns, we will apply a Box-Cox transformation. The best power ($\lambda$) is estimated by maximizing log-likelihood.

```{r}
secondReg = boxcox(firstReg)
power=secondReg$x[which.max(secondReg$y)]
BCTransform <- function(y, lambda=0) {
     if (lambda == 0L) { log(y) }
     else { (y^lambda - 1) / lambda }
  }
members_boxcox = BCTransform(data$members, power)
thirdReg <- lm(members_boxcox~score+source+status+favorites+producerCount+licensorCount+studioCount+genreCount+ Action + Adventure + Cars  +  Comedy  +  Dementia  +  Demons  +  Drama  + Ecchi  + Fantasy  + Game  +  Harem  + Hentai  +  Historical  +  Horror  +  Josei  +  Kids  +  Magic  +   `Martial Arts`  +   Mecha  + Military  + Music  +    Mystery   +   Parody   +  Police  +   Psychological  +  Romance  +  Samurai  + School  +   `Sci-Fi`  +   Seinen  + Shoujo  +  `Shoujo Ai`  +  Shounen  +  `Shounen Ai`  + `Slice of Life`  + Space   +  Sports  +  `Super Power`  +  Supernatural  +   Thriller  +  Vampire  + Yaoi  +  Yuri + duration + episodes + type + rating + factor(yearAired), data = data)

par(mfrow=c(2,3))
plot(thirdReg)
boxplot(thirdReg$residuals, main = "Boxplot of residuals")
hist(thirdReg$residuals, main = "Histogram of residuals", xlab = "Residuals")
```

## Outlier removal

After applying the Box-Cox transformation, we will remove high leverage points, so that the estimated parameter for each genre better reflect the true value. The method we will use to remove high leverage points is measure the Cook's Distance of each observation. Then, using a standard 4/(n-k-1) criterion, we will remove all observations with a Cook's Distance greater than 6.1293x10^(-4). These observations are high leverage points.

```{r}
cooksDistance <- cooks.distance(thirdReg)

# Plot the Cook's Distance using the traditional 4/n criterion
plot(cooksDistance, pch="*", cex=2, main="High Leverage Points by Cook's distance")  # plot cook's distance
abline(h = 4/(6668-141-1), col="red")  # add cutoff line
text(x=1:length(cooksDistance)+1, y=cooksDistance, labels=ifelse(cooksDistance>4/(6668-141-1), names(cooksDistance),""), col="red")  # add labels
```

```{r}
highLeveragePoints <- as.numeric(names(cooksDistance)[cooksDistance > (4/(6668-141-1))])
highLeveragePoints = c(highLeveragePoints,1193, 1360, 1504, 5918, 6135, 1142, 1300, 1997 )
```

```{r}
dataMinusOutliers <- data[-sort(highLeveragePoints), ]

fourthReg <- lm(members_boxcox[-sort(highLeveragePoints)]~score+source+status+favorites+producerCount+licensorCount+studioCount+genreCount+ Action + Adventure + Cars  +  Comedy  +  Dementia  +  Demons  +  Drama  + Ecchi  + Fantasy  + Game  +  Harem  + Hentai  +  Historical  +  Horror  +  Josei  +  Kids  +  Magic  +   `Martial Arts`  +   Mecha  + Military  + Music  +    Mystery   +   Parody   +  Police  +   Psychological  +  Romance  +  Samurai  + School  +   `Sci-Fi`  +   Seinen  + Shoujo  +  `Shoujo Ai`  +  Shounen  +  `Shounen Ai`  + `Slice of Life`  + Space   +  Sports  +  `Super Power`  +  Supernatural  +   Thriller  +  Vampire  + Yaoi  +  Yuri + duration + episodes + type + rating + factor(yearAired), data = dataMinusOutliers)

par(mfrow=c(2,3))
plot(fourthReg)
boxplot(fourthReg$residuals, main = "Boxplot of residuals")
hist(fourthReg$residuals, main = "Histogram of residuals")
```

After removing the high leverage points, the diagnostic plots appear much better. The model no longer appears to suffer from non-normally distributed errors, heteroskedasticity, and high leverage points. It is now appropriate to analyze the coefficients of each genre.

```{r}
summary(fourthReg)
```

To determine which genres are significant, we will use a standard $\alpha = 0.05$. However, we will also apply a Bonferroni Correction, which results in comparing the p-values to  $\frac{0.05}{43} = 0.00116279$ (we divided by 43 because there are 43 total genres). Based on this threshold, there are no significant genres. This indicates that genres do not play a significant role in determining the popularity ($\members$) of an anime. It is important to note that our model is not perfect. We had limited data, and we did the best we could with the data.

## Predicting Members

With causal inference, we transformed our initial model and removed outliers from our dataset with the goal of meeting all Gauss Markov assumptions such that OLS is BLUE. We didn't care about model complexity since our goal was to produce unbiased, consistent, and efficient estiamtes of the effect that different genres had on popularity. Ultimately, due to the weakness of cross secitonal data, we weren't able to meet all the requirements for OLS to be BLUE. 

## "All models are wrong, but some are useful"

With prediction, our priorities shift. We're not so much worried about whether or not a model is "wrong," but instead whether or not it is useful in predicting $members$. To find the best variables that predict $members$, we first randomly divide our full dataset into training data and testing data—each composing 50% of the full dataset. Next, using the training dataset and starting with the empty model, we will perform bidirectional stepwise selection using AIC and BIC. The total possible varibales to include in our model is the same as our first model from causal inference, excluding genres. We opted not to include genres to simplify the overall model. Furthermore, we removed $yearAired$ from consideration since animes released in the future will never have $yearAired$ values of the past.

```{r}
set.seed(2020141)
trainIndex <- sample(6668, as.integer(6668*0.5))
trainingData= data[trainIndex,]
testingData = data[-trainIndex,]

stepwiseSelectionAIC <- step(lm(members~1, data = trainingData),
                          scope = ~score+source+status+favorites+producerCount+licensorCount+studioCount+genreCount+ duration + episodes + type + rating,
                          direction = "both",  k = 2,
                          trace = 0)

stepwiseSelectionBIC <- step(lm(members~1, data = trainingData),
                          scope = ~score+source+status+favorites+producerCount+licensorCount+studioCount+genreCount+ duration + episodes + type + rating,
                          direction = "both",  k = log(as.integer(6668*0.5)),
                          trace = 0)
```


Starting with the empty model and the **training dataset**, bidirectional stepwise selection minimizing **AIC**, results in the model:
\begin{gather}
members  \sim favorites + producerCount + score + source + licensorCount + type + rating \\
+ genreCount +episodes + studioCount + duration\\
\end{gather}


Starting with the empty model and the **testing dataset**, bidirectional stepwise selection minimizing **BIC**, results in the model:
\begin{gather}
members \sim favorites + producerCount + score + licensorCount + source + type + genreCount + episodes\\
\end{gather}

The difference between the model that minimizes AIC and the model that minimizes BIC is the inclusion of $rating$, $studioCount$, and $duration$ in the AIC model. Now, we must determine whether the inclusion of these variables in the AIC model is "worth" the complexity that they bring. To determine this, we will compare $adj. R^2$ values, which take into consideration the number of parameters. The AIC model (1) has the higher $adj. R^2$ value than the BIC model (2), which suggests that the inclusion of $rating$, $studioCount$, and $duration$ is worth the additional complexity.



<div align="center">
```{r, results = 'asis'}
stepwiseSelectionAIC$AIC <- AIC(stepwiseSelectionAIC)
stepwiseSelectionAIC$BIC <- BIC(stepwiseSelectionAIC)

stepwiseSelectionBIC$AIC <- AIC(stepwiseSelectionBIC)
stepwiseSelectionBIC$BIC <- BIC(stepwiseSelectionBIC)

stargazer(stepwiseSelectionAIC, stepwiseSelectionBIC, type = "html", keep.stat = c("aic", "bic","adj.rsq","n"), omit.table.layout = "tn")
```
</div>


To further test whether the AIC model is better than the BIC model at prediction, we will use both models to predict $members$ with the **testing data**. The $adj. R^2$ results for the AIC model and BIC model are close, but the results confirm that the AIC model (1) is indeed better than the BIC model (2). 

<div align="center">
```{r, results= 'asis'}
testDataAIC <- lm(stepwiseSelectionAIC$model, data = testingData)
testDataBIC <-lm(stepwiseSelectionBIC$model, data = testingData)

testDataAIC$AIC <- AIC(testDataAIC)
testDataAIC$BIC <- BIC(testDataAIC)

testDataBIC$AIC <- AIC(testDataBIC)
testDataBIC$BIC <- BIC(testDataBIC)

stargazer(testDataAIC, testDataBIC, type = "html", keep.stat = c("aic", "bic","adj.rsq","n"), omit.table.layout = "tn")
```
</div>

# Conclusion

When discussing the relationship between genre and popularity, we looked at the p-values of the our initial model and applied a Bonferroni correction where we set a threshold for a standard alpha of our choosing and divided that by the 43 genres that exist, so that we can have a defined alpha as our threshold. For the first time we applied the correction, we used an original alpha of 0.05 and divided that by 43 to give us an alpha of 0.00116279. We then checked to see if the model had significant genres for this threshold, but unfortunately, there wasn’t a genre that met this requirement since it was greater than our calculated alpha. This would mean that genre isn’t a significant variable overall, which could mean that users are indifferent towards the anime’s genre itself being an impact on its popularity.

To assess the quality of our model, we took out genre and ran a stepwise regression on this model. We created 2 models based on Akaike information criterion (AIC) and Bayes information criterion (BIC) using half our data as training data. We then assessed the other half of our data based on this model. The results we got showed our model based on AIC was better fitting of our data based adjusted r-squared values.

# Bibliography

https://www.liveabout.com/what-is-anime-144982
https://en.wikipedia.org/wiki/History_of_anime
https://animemotivation.com/anime-companies-bankrupt/
http://www.css.cornell.edu/faculty/dgr2/_static/files/R_html/Transformations.html
http://www.sthda.com/english/articles/38-regression-model-validation/158-regression-model-accuracy-metrics-r-square-aic-bic-cp-and-more/


```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}

```